# Technical Implementation Plan: Podcast Website

## Overview

Build a podcast website using Astro and Tailwind CSS that displays podcast cards on the homepage. Each card links to a podcast detail page with multiple audio tracks, real-time progress tracking, and clickable transcript navigation.

## Data Structure Analysis

### Input Format (JSON)
```json
{
  "summary": "Description of the podcast content",
  "segments": [
    {
      "speaker": "Speaker 1",
      "timestamp": "00:08",
      "content": "Transcript text...",
      "language": "English",
      "language_code": "en",
      "translation": null,
      "emotion": "neutral"
    }
  ]
}
```

### Resource Organization
```
resources/
├── 60/                           # Podcast episode folder
│   ├── englishpod_C0060dg.mp3   # Audio variant (dg)
│   ├── englishpod_C0060dg.json  # Transcript for dg
│   ├── englishpod_C0060pb.mp3   # Audio variant (pb)
│   ├── englishpod_C0060pb.json  # Transcript for pb
│   ├── englishpod_C0060rv.mp3   # Audio variant (rv)
│   └── englishpod_C0060rv.json  # Transcript for rv
└── 78/
    └── ...
```

---

## Architecture

### Project Structure
```
src/
├── components/
│   ├── AudioPlayer.astro        # Audio player with progress bar
│   ├── PodcastCard.astro        # Card component for homepage
│   ├── TrackList.astro          # List of audio tracks (dg, pb, rv)
│   ├── Transcript.astro         # Clickable transcript display
│   └── TranscriptSegment.astro  # Individual transcript segment
├── layouts/
│   └── BaseLayout.astro         # Main layout with Tailwind
├── pages/
│   ├── index.astro              # Homepage with podcast cards
│   └── podcast/
│       └── [id].astro           # Dynamic podcast detail page
├── lib/
│   └── podcasts.ts              # Data loading utilities
├── types/
│   └── podcast.ts               # TypeScript interfaces
└── styles/
    └── global.css               # Global styles + Tailwind imports
```

---

## Implementation Steps

### Step 1: Install Tailwind CSS

```bash
npx astro add tailwind
```

Update `astro.config.mjs`:
```javascript
import tailwind from '@astrojs/tailwind';

export default defineConfig({
  integrations: [mdx(), sitemap(), tailwind()],
});
```

### Step 2: Define TypeScript Interfaces

**`src/types/podcast.ts`**
```typescript
export interface TranscriptSegment {
  speaker: string;
  timestamp: string;        // "MM:SS" format
  content: string;
  language: string;
  language_code: string;
  translation: string | null;
  emotion: string;
}

export interface TranscriptData {
  summary: string;
  segments: TranscriptSegment[];
}

export interface AudioTrack {
  id: string;              // "dg", "pb", "rv"
  label: string;           // Display name
  audioPath: string;       // Path to MP3 file
  transcript: TranscriptData;
}

export interface Podcast {
  id: string;              // Folder name (e.g., "60", "78")
  title: string;           // Generated from folder/filename
  tracks: AudioTrack[];
}
```

### Step 3: Data Loading Utilities

**`src/lib/podcasts.ts`**
```typescript
import type { Podcast, AudioTrack, TranscriptData } from '../types/podcast';
import fs from 'node:fs';
import path from 'node:path';

const RESOURCES_DIR = 'resources';

// Map track suffixes to display labels
const TRACK_LABELS: Record<string, string> = {
  dg: 'Dialogue',
  pb: 'Vocabulary',
  rv: 'Review'
};

export function parseTimestamp(timestamp: string): number {
  const [minutes, seconds] = timestamp.split(':').map(Number);
  return minutes * 60 + seconds;
}

export function formatTime(seconds: number): string {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
}

export async function getAllPodcasts(): Promise<Podcast[]> {
  const resourcesPath = path.join(process.cwd(), RESOURCES_DIR);
  const folders = fs.readdirSync(resourcesPath, { withFileTypes: true })
    .filter(dirent => dirent.isDirectory())
    .map(dirent => dirent.name);

  const podcasts: Podcast[] = [];

  for (const folder of folders) {
    const podcast = await getPodcastById(folder);
    if (podcast) {
      podcasts.push(podcast);
    }
  }

  return podcasts.sort((a, b) => a.id.localeCompare(b.id, undefined, { numeric: true }));
}

export async function getPodcastById(id: string): Promise<Podcast | null> {
  const folderPath = path.join(process.cwd(), RESOURCES_DIR, id);

  if (!fs.existsSync(folderPath)) {
    return null;
  }

  const files = fs.readdirSync(folderPath);
  const mp3Files = files.filter(f => f.endsWith('.mp3'));

  const tracks: AudioTrack[] = [];

  for (const mp3File of mp3Files) {
    // Extract track type from filename (e.g., "dg", "pb", "rv")
    const match = mp3File.match(/([a-z]{2})\.mp3$/);
    if (!match) continue;

    const trackType = match[1];
    const jsonFile = mp3File.replace('.mp3', '.json');
    const jsonPath = path.join(folderPath, jsonFile);

    if (!fs.existsSync(jsonPath)) continue;

    const transcriptData: TranscriptData = JSON.parse(
      fs.readFileSync(jsonPath, 'utf-8')
    );

    tracks.push({
      id: trackType,
      label: TRACK_LABELS[trackType] || trackType.toUpperCase(),
      audioPath: `/${RESOURCES_DIR}/${id}/${mp3File}`,
      transcript: transcriptData
    });
  }

  // Sort tracks: dg first, then pb, then rv
  const trackOrder = ['dg', 'pb', 'rv'];
  tracks.sort((a, b) => trackOrder.indexOf(a.id) - trackOrder.indexOf(b.id));

  return {
    id,
    title: `Episode ${id}`,
    tracks
  };
}
```

### Step 4: Copy Resources to Public Folder

Configure Astro to serve static audio files. Create a symbolic link or copy resources:

**Option A: Symlink (Development)**
```bash
ln -s ../resources public/resources
```

**Option B: Configure in `astro.config.mjs`**
```javascript
export default defineConfig({
  publicDir: 'public',
  vite: {
    server: {
      fs: {
        allow: ['resources']
      }
    }
  }
});
```

### Step 5: Base Layout with Tailwind

**`src/layouts/BaseLayout.astro`**
```astro
---
interface Props {
  title: string;
  description?: string;
}

const { title, description = 'Podcast Website' } = Astro.props;
---
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content={description}>
  <title>{title}</title>
</head>
<body class="bg-gray-50 min-h-screen">
  <header class="bg-white shadow-sm">
    <nav class="max-w-6xl mx-auto px-4 py-4">
      <a href="/" class="text-xl font-bold text-gray-900">Podcasts</a>
    </nav>
  </header>
  <main class="max-w-6xl mx-auto px-4 py-8">
    <slot />
  </main>
</body>
</html>
```

### Step 6: Podcast Card Component

**`src/components/PodcastCard.astro`**
```astro
---
import type { Podcast } from '../types/podcast';

interface Props {
  podcast: Podcast;
}

const { podcast } = Astro.props;
const firstTrack = podcast.tracks[0];
const summary = firstTrack?.transcript.summary || 'No description available';
---
<a
  href={`/podcast/${podcast.id}`}
  class="block bg-white rounded-lg shadow-md hover:shadow-lg transition-shadow p-6"
>
  <h2 class="text-xl font-semibold text-gray-900 mb-2">{podcast.title}</h2>
  <p class="text-gray-600 text-sm line-clamp-3">{summary}</p>
  <div class="mt-4 flex gap-2">
    {podcast.tracks.map(track => (
      <span class="px-2 py-1 bg-blue-100 text-blue-800 text-xs rounded">
        {track.label}
      </span>
    ))}
  </div>
</a>
```

### Step 7: Homepage

**`src/pages/index.astro`**
```astro
---
import BaseLayout from '../layouts/BaseLayout.astro';
import PodcastCard from '../components/PodcastCard.astro';
import { getAllPodcasts } from '../lib/podcasts';

const podcasts = await getAllPodcasts();
---
<BaseLayout title="Podcasts">
  <h1 class="text-3xl font-bold text-gray-900 mb-8">All Podcasts</h1>
  <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
    {podcasts.map(podcast => (
      <PodcastCard podcast={podcast} />
    ))}
  </div>
</BaseLayout>
```

### Step 8: Transcript Segment Component

**`src/components/TranscriptSegment.astro`**
```astro
---
import type { TranscriptSegment } from '../types/podcast';

interface Props {
  segment: TranscriptSegment;
  index: number;
}

const { segment, index } = Astro.props;

// Emotion to color mapping
const emotionColors: Record<string, string> = {
  neutral: 'border-gray-200',
  happy: 'border-green-200 bg-green-50',
  sad: 'border-blue-200 bg-blue-50',
  angry: 'border-red-200 bg-red-50'
};

const borderColor = emotionColors[segment.emotion] || emotionColors.neutral;
---
<div
  class={`transcript-segment p-3 rounded border-l-4 cursor-pointer hover:bg-gray-100 transition-colors ${borderColor}`}
  data-timestamp={segment.timestamp}
  data-index={index}
>
  <div class="flex items-center gap-2 mb-1">
    <span class="text-xs font-mono text-blue-600 hover:underline timestamp-link">
      {segment.timestamp}
    </span>
    <span class="text-sm font-medium text-gray-700">{segment.speaker}</span>
    {segment.language_code !== 'en' && (
      <span class="text-xs px-1 bg-yellow-100 text-yellow-800 rounded">
        {segment.language}
      </span>
    )}
  </div>
  <p class="text-gray-800">{segment.content}</p>
  {segment.translation && (
    <p class="text-gray-500 text-sm italic mt-1">{segment.translation}</p>
  )}
</div>
```

### Step 9: Audio Player with Real-time Progress

**`src/components/AudioPlayer.astro`**
```astro
---
interface Props {
  trackId: string;
}

const { trackId } = Astro.props;
---
<div class="audio-player bg-white rounded-lg shadow p-4" data-track-id={trackId}>
  <audio id={`audio-${trackId}`} class="hidden"></audio>

  <div class="flex items-center gap-4">
    <!-- Play/Pause Button -->
    <button
      class="play-btn w-12 h-12 flex items-center justify-center bg-blue-600 hover:bg-blue-700 text-white rounded-full transition-colors"
      aria-label="Play"
    >
      <svg class="play-icon w-5 h-5" fill="currentColor" viewBox="0 0 20 20">
        <path d="M6.3 2.841A1.5 1.5 0 004 4.11v11.78a1.5 1.5 0 002.3 1.269l9.344-5.89a1.5 1.5 0 000-2.538L6.3 2.84z"/>
      </svg>
      <svg class="pause-icon w-5 h-5 hidden" fill="currentColor" viewBox="0 0 20 20">
        <path d="M5.75 3a.75.75 0 00-.75.75v12.5c0 .414.336.75.75.75h1.5a.75.75 0 00.75-.75V3.75A.75.75 0 007.25 3h-1.5zM12.75 3a.75.75 0 00-.75.75v12.5c0 .414.336.75.75.75h1.5a.75.75 0 00.75-.75V3.75a.75.75 0 00-.75-.75h-1.5z"/>
      </svg>
    </button>

    <!-- Progress Bar -->
    <div class="flex-1">
      <div class="progress-container h-2 bg-gray-200 rounded-full cursor-pointer relative">
        <div class="progress-bar h-full bg-blue-600 rounded-full w-0 transition-all"></div>
        <div class="progress-handle absolute top-1/2 -translate-y-1/2 w-4 h-4 bg-blue-600 rounded-full -ml-2 opacity-0 hover:opacity-100 transition-opacity" style="left: 0%"></div>
      </div>
      <div class="flex justify-between text-xs text-gray-500 mt-1">
        <span class="current-time">00:00</span>
        <span class="duration">00:00</span>
      </div>
    </div>

    <!-- Volume Control -->
    <div class="flex items-center gap-2">
      <button class="mute-btn text-gray-600 hover:text-gray-800" aria-label="Mute">
        <svg class="volume-icon w-5 h-5" fill="currentColor" viewBox="0 0 20 20">
          <path d="M10 3.75a.75.75 0 00-1.264-.546L4.703 7H3.167a.75.75 0 00-.7.48A6.985 6.985 0 002 10c0 .887.165 1.737.468 2.52.111.29.39.48.7.48h1.535l4.033 3.796A.75.75 0 0010 16.25V3.75zM15.95 5.05a.75.75 0 00-1.06 1.061 5.5 5.5 0 010 7.778.75.75 0 001.06 1.06 7 7 0 000-9.899z"/>
        </svg>
      </button>
      <input type="range" class="volume-slider w-20 h-1" min="0" max="1" step="0.1" value="1">
    </div>
  </div>
</div>
```

### Step 10: Client-Side JavaScript for Audio Player

**`src/scripts/audio-player.ts`**
```typescript
interface AudioPlayerState {
  audio: HTMLAudioElement;
  isPlaying: boolean;
  currentSegmentIndex: number;
}

function parseTimestamp(timestamp: string): number {
  const [minutes, seconds] = timestamp.split(':').map(Number);
  return minutes * 60 + seconds;
}

function formatTime(seconds: number): string {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
}

function initAudioPlayer(container: HTMLElement) {
  const trackId = container.dataset.trackId!;
  const audio = container.querySelector('audio') as HTMLAudioElement;
  const playBtn = container.querySelector('.play-btn') as HTMLButtonElement;
  const playIcon = container.querySelector('.play-icon') as SVGElement;
  const pauseIcon = container.querySelector('.pause-icon') as SVGElement;
  const progressContainer = container.querySelector('.progress-container') as HTMLElement;
  const progressBar = container.querySelector('.progress-bar') as HTMLElement;
  const currentTimeEl = container.querySelector('.current-time') as HTMLElement;
  const durationEl = container.querySelector('.duration') as HTMLElement;
  const volumeSlider = container.querySelector('.volume-slider') as HTMLInputElement;
  const muteBtn = container.querySelector('.mute-btn') as HTMLButtonElement;

  // Get transcript segments
  const transcriptContainer = document.querySelector(`[data-transcript-for="${trackId}"]`);
  const segments = transcriptContainer?.querySelectorAll('.transcript-segment') || [];

  let state: AudioPlayerState = {
    audio,
    isPlaying: false,
    currentSegmentIndex: -1
  };

  // Play/Pause toggle
  playBtn.addEventListener('click', () => {
    if (state.isPlaying) {
      audio.pause();
    } else {
      audio.play();
    }
  });

  audio.addEventListener('play', () => {
    state.isPlaying = true;
    playIcon.classList.add('hidden');
    pauseIcon.classList.remove('hidden');
  });

  audio.addEventListener('pause', () => {
    state.isPlaying = false;
    playIcon.classList.remove('hidden');
    pauseIcon.classList.add('hidden');
  });

  // Time update - real-time progress
  audio.addEventListener('timeupdate', () => {
    const progress = (audio.currentTime / audio.duration) * 100;
    progressBar.style.width = `${progress}%`;
    currentTimeEl.textContent = formatTime(audio.currentTime);

    // Highlight current transcript segment
    highlightCurrentSegment(audio.currentTime);
  });

  audio.addEventListener('loadedmetadata', () => {
    durationEl.textContent = formatTime(audio.duration);
  });

  // Click on progress bar to seek
  progressContainer.addEventListener('click', (e) => {
    const rect = progressContainer.getBoundingClientRect();
    const percent = (e.clientX - rect.left) / rect.width;
    audio.currentTime = percent * audio.duration;
  });

  // Volume control
  volumeSlider.addEventListener('input', () => {
    audio.volume = parseFloat(volumeSlider.value);
  });

  muteBtn.addEventListener('click', () => {
    audio.muted = !audio.muted;
    volumeSlider.value = audio.muted ? '0' : audio.volume.toString();
  });

  // Click on transcript to seek
  segments.forEach((segment) => {
    segment.addEventListener('click', () => {
      const timestamp = (segment as HTMLElement).dataset.timestamp!;
      audio.currentTime = parseTimestamp(timestamp);
      if (!state.isPlaying) {
        audio.play();
      }
    });
  });

  // Highlight current segment based on playback time
  function highlightCurrentSegment(currentTime: number) {
    let activeIndex = -1;

    segments.forEach((segment, index) => {
      const timestamp = parseTimestamp((segment as HTMLElement).dataset.timestamp!);
      const nextSegment = segments[index + 1];
      const nextTimestamp = nextSegment
        ? parseTimestamp((nextSegment as HTMLElement).dataset.timestamp!)
        : Infinity;

      if (currentTime >= timestamp && currentTime < nextTimestamp) {
        activeIndex = index;
      }
    });

    if (activeIndex !== state.currentSegmentIndex) {
      // Remove highlight from previous segment
      segments.forEach(s => s.classList.remove('bg-blue-100', 'border-blue-500'));

      // Add highlight to current segment
      if (activeIndex >= 0) {
        segments[activeIndex].classList.add('bg-blue-100', 'border-blue-500');
        // Auto-scroll to segment
        segments[activeIndex].scrollIntoView({
          behavior: 'smooth',
          block: 'nearest'
        });
      }

      state.currentSegmentIndex = activeIndex;
    }
  }
}

// Initialize all audio players on page load
document.addEventListener('DOMContentLoaded', () => {
  document.querySelectorAll('.audio-player').forEach(player => {
    initAudioPlayer(player as HTMLElement);
  });
});
```

### Step 11: Podcast Detail Page

**`src/pages/podcast/[id].astro`**
```astro
---
import BaseLayout from '../../layouts/BaseLayout.astro';
import AudioPlayer from '../../components/AudioPlayer.astro';
import TranscriptSegment from '../../components/TranscriptSegment.astro';
import { getAllPodcasts, getPodcastById } from '../../lib/podcasts';

export async function getStaticPaths() {
  const podcasts = await getAllPodcasts();
  return podcasts.map(podcast => ({
    params: { id: podcast.id }
  }));
}

const { id } = Astro.params;
const podcast = await getPodcastById(id!);

if (!podcast) {
  return Astro.redirect('/404');
}
---
<BaseLayout title={podcast.title}>
  <a href="/" class="text-blue-600 hover:underline mb-4 inline-block">&larr; Back to all podcasts</a>

  <h1 class="text-3xl font-bold text-gray-900 mb-6">{podcast.title}</h1>

  <!-- Track Tabs -->
  <div class="mb-6">
    <div class="flex border-b border-gray-200">
      {podcast.tracks.map((track, index) => (
        <button
          class={`track-tab px-4 py-2 font-medium text-sm border-b-2 transition-colors ${
            index === 0
              ? 'border-blue-600 text-blue-600'
              : 'border-transparent text-gray-500 hover:text-gray-700'
          }`}
          data-track={track.id}
        >
          {track.label}
        </button>
      ))}
    </div>
  </div>

  <!-- Track Content -->
  {podcast.tracks.map((track, index) => (
    <div
      class={`track-content ${index === 0 ? '' : 'hidden'}`}
      data-track-content={track.id}
    >
      <!-- Summary -->
      <div class="bg-gray-100 rounded-lg p-4 mb-6">
        <h2 class="font-semibold text-gray-800 mb-2">Summary</h2>
        <p class="text-gray-700">{track.transcript.summary}</p>
      </div>

      <!-- Audio Player -->
      <div class="mb-6">
        <AudioPlayer trackId={track.id} />
        <script define:vars={{ audioPath: track.audioPath, trackId: track.id }}>
          document.addEventListener('DOMContentLoaded', () => {
            const audio = document.querySelector(`#audio-${trackId}`);
            if (audio) audio.src = audioPath;
          });
        </script>
      </div>

      <!-- Transcript -->
      <div
        class="transcript-container space-y-2 max-h-96 overflow-y-auto"
        data-transcript-for={track.id}
      >
        <h2 class="font-semibold text-gray-800 mb-4 sticky top-0 bg-gray-50 py-2">Transcript</h2>
        {track.transcript.segments.map((segment, i) => (
          <TranscriptSegment segment={segment} index={i} />
        ))}
      </div>
    </div>
  ))}

  <!-- Tab Switching Script -->
  <script>
    document.querySelectorAll('.track-tab').forEach(tab => {
      tab.addEventListener('click', () => {
        const trackId = (tab as HTMLElement).dataset.track;

        // Update tab styles
        document.querySelectorAll('.track-tab').forEach(t => {
          t.classList.remove('border-blue-600', 'text-blue-600');
          t.classList.add('border-transparent', 'text-gray-500');
        });
        tab.classList.add('border-blue-600', 'text-blue-600');
        tab.classList.remove('border-transparent', 'text-gray-500');

        // Show/hide content
        document.querySelectorAll('.track-content').forEach(content => {
          content.classList.add('hidden');
        });
        document.querySelector(`[data-track-content="${trackId}"]`)?.classList.remove('hidden');
      });
    });
  </script>
</BaseLayout>

<script src="../../scripts/audio-player.ts"></script>
```

---

## Key Features Implementation Details

### 1. Real-time Progress Display
- Use `timeupdate` event on HTMLAudioElement (fires ~4 times per second)
- Update progress bar width and current time display
- Calculate current segment based on timestamp comparison

### 2. Clickable Transcript Navigation
- Each segment has `data-timestamp` attribute
- Click handler parses timestamp and sets `audio.currentTime`
- Smooth scroll to active segment during playback

### 3. Visual Feedback
- Active segment highlighted with background color change
- Emotion-based border colors for visual transcript scanning
- Smooth transitions for all interactive elements

### 4. Multiple Audio Tracks
- Tab-based navigation between tracks (dg, pb, rv)
- Each track has independent audio player and transcript
- Track state preserved when switching tabs

---

## Build & Deployment

### Development
```bash
npm install
npm run dev
```

### Production Build
```bash
npm run build
```

### Deployment Notes
- Audio files should be served from a CDN for better performance
- Consider lazy-loading transcripts for very long podcasts
- Add service worker for offline playback support

---

## Future Enhancements

1. **Playback Speed Control**: Add 0.5x, 1x, 1.5x, 2x speed options
2. **Keyboard Shortcuts**: Space for play/pause, arrow keys for seeking
3. **Search in Transcript**: Filter segments by text content
4. **Download Option**: Allow downloading MP3 files
5. **Bookmarks**: Save favorite timestamps
6. **Dark Mode**: Theme toggle support
